#!/usr/bin/env python
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.

"""
Implements cfn-signal CloudFormation functionality
"""
import argparse
import logging
import os
import subprocess
import random
import sys


log_format = '%(levelname)s [%(asctime)s] %(message)s'
logging.basicConfig(format=log_format, level=logging.DEBUG)

LOG = logging.getLogger('cfntools')
log_file_name = "/var/log/cfn-push-stats.log"
file_handler = logging.FileHandler(log_file_name)
file_handler.setFormatter(logging.Formatter(log_format))
LOG.addHandler(file_handler)

try:
    import psutil
except ImportError:
    LOG.warn("psutil not available. If you want process and memory "
            "statistics, you need to install it.")
#
#  --aws-credential-file=PATH  Specifies the location of the file with AWS
#                              credentials.
#  --aws-access-key-id=VALUE   Specifies the AWS access key ID to use to
#                              identify the caller.
#  --aws-secret-key=VALUE      Specifies the AWS secret key to use to sign
#                              the request.
#  --from-cron  Specifies that this script is running from cron.
#
# Examples
#
# To perform a simple test run without posting data to Amazon CloudWatch
#
#  ./mon-put-instance-data.pl --mem-util --verify --verbose
#
# To set a five-minute cron schedule to report memory and disk space utilization to CloudWatch
#
#  */5 * * * * ~/aws-scripts-mon/mon-put-instance-data.pl --mem-util --disk-space-util --disk-path=/ --from-cron
#

if os.path.exists('/opt/aws/bin'):
    sys.path.insert(0, '/opt/aws/bin')
    from cfn_helper import *
else:
    from heat.cfntools.cfn_helper import *

KILO = 1024
MEGA = 1048576
GIGA = 1073741824
unit_map = {'bytes': 1,
    'kilobytes': KILO,
    'megabytes': MEGA,
    'gigabytes': GIGA}

description = " "
parser = argparse.ArgumentParser(description=description)
parser.add_argument('-v', '--verbose', action="store_true",
                    help="Verbose logging", required=False)
parser.add_argument('--service-failure', required=False, action="store_true",
                    help='Reports a service falure.')
parser.add_argument('--mem-util', required=False, action="store_true",
                    help='Reports memory utilization in percentages.')
parser.add_argument('--mem-used', required=False, action="store_true",
                    help='Reports memory used (excluding cache and buffers) in megabytes.')
parser.add_argument('--mem-avail', required=False, action="store_true",
                    help='Reports available memory (including cache and buffers) in megabytes.')
parser.add_argument('--swap-util', required=False, action="store_true",
                    help='Reports swap utilization in percentages.')
parser.add_argument('--swap-used', required=False, action="store_true",
                    help='Reports allocated swap space in megabytes.')
parser.add_argument('--disk-space-util', required=False, action="store_true",
                    help='Reports disk space utilization in percentages.')
parser.add_argument('--disk-space-used', required=False, action="store_true",
                    help='Reports allocated disk space in gigabytes.')
parser.add_argument('--disk-space-avail',required=False, action="store_true",
                    help='Reports available disk space in gigabytes.')
parser.add_argument('--memory-units', required=False, default='megabytes',
                    help='Specifies units for memory metrics.')
parser.add_argument('--disk-units', required=False, default='megabytes',
                    help='Specifies units for disk metrics.')
parser.add_argument('--disk-path', required=False, default='/',
                    help='Selects the disk by the path on which to report.')
parser.add_argument('--cpu-util', required=False, action="store_true",
                    help='Reports cpu utilization in percentages.')
parser.add_argument('--haproxy', required=False, action='store_true',
                    help='Reports HAProxy loadbalancer usage.')
parser.add_argument('--heartbeat', required=False, action='store_true',
                    help='Sends a Heartbeat.')
parser.add_argument('--watch', required=True,
                    help='the name of the watch to post to.')
args = parser.parse_args()

server_url = metadata_server_url()
if not server_url:
    LOG.error('can not get the metadata_server_url')
    exit(1)
url = '%sstats/%s/data/' % (server_url, args.watch)

data = {'Namespace': 'system/linux'}

# service failure
# ===============
if args.service_failure:
    data['ServiceFailure'] = {
        'Value': 1,
        'Units': 'Counter'}

# heatbeat
# ========
if args.heartbeat:
    data['Heartbeat'] = {
        'Value': 1,
        'Units': 'Counter'}

# memory space
# ============
if args.mem_util or args.mem_used or args.mem_avail:
    mem = psutil.phymem_usage()
if args.mem_util:
    data['MemoryUtilization'] = {
        'Value': mem.percent,
        'Units': 'Percent'}
if args.mem_used:
    data['MemoryUsed'] = {
        'Value': mem.used / unit_map[args.memory_units],
        'Units': args.memory_units}
if args.mem_avail:
    data['MemoryAvailable'] = {
        'Value': mem.free / unit_map[args.memory_units],
        'Units': args.memory_units}

# swap space
# ==========
if args.swap_util or args.swap_used:
    swap = psutil.virtmem_usage()
if args.swap_util:
    data['SwapUtilization'] = {
        'Value': swap.percent,
        'Units': 'Percent'}
if args.swap_used:
    data['SwapUsed'] = {
        'Value': swap.used / unit_map[args.memory_units],
        'Units': args.memory_units}

# disk space
# ==========
if args.disk_space_util or args.disk_space_used or args.disk_space_avail:
    disk = psutil.disk_usage(args.disk_path)
if args.disk_space_util:
    data['DiskSpaceUtilization'] = {
        'Value': disk.percent,
        'Units': 'Percent'}
if args.disk_space_used:
    data['DiskSpaceUsed'] = {
        'Value': disk.used / unit_map[args.disk_units],
        'Units': args.disk_units}
if args.disk_space_avail:
    data['DiskSpaceAvailable'] = {
        'Value': disk.free / unit_map[args.disk_units],
        'Units': args.disk_units}

# cpu utilization
# ===============
if args.cpu_util:
    # blocks for 1 second.
    cpu_percent = psutil.cpu_percent(interval=1)
    data['CPUUtilization'] = {
        'Value': cpu_percent,
        'Units': 'Percent'}

# HAProxy
# =======
def parse_haproxy_unix_socket(res):
    # http://docs.amazonwebservices.com/ElasticLoadBalancing/latest
    # /DeveloperGuide/US_MonitoringLoadBalancerWithCW.html

    type_map = {'FRONTEND': '0', 'BACKEND': '1', 'SERVER': '2', 'SOCKET': '3'}
    num_map = {'status': 17, 'svname': 1, 'check_duration': 38, 'type': 32,
               'req_tot': 48, 'hrsp_2xx': 40, 'hrsp_3xx': 41, 'hrsp_4xx': 42,
               'hrsp_5xx': 43}

    def add_stat(key, value, unit='Counter'):
        res[key] = {'Value': value,
                     'Units': unit}

    echo = subprocess.Popen(['echo', 'show stat'],
                            stdout=subprocess.PIPE)
    socat = subprocess.Popen(['socat', 'stdio', '/tmp/.haproxy-stats'],
                             stdin=echo.stdout,
                             stdout=subprocess.PIPE)
    end_pipe = socat.stdout
    raw = [l.strip('\n').split(',') for l in end_pipe
                                    if l[0] != '#' and len(l) > 2]
    latency = 0
    up_count = 0
    down_count = 0
    for f in raw:
        if f[num_map['type']] == type_map['FRONTEND']:
            add_stat('RequestCount', f[num_map['req_tot']])
            add_stat('HTTPCode_ELB_4XX', f[num_map['hrsp_4xx']])
            add_stat('HTTPCode_ELB_5XX', f[num_map['hrsp_5xx']])
        elif f[num_map['type']] == type_map['BACKEND']:
            add_stat('HTTPCode_Backend_2XX', f[num_map['hrsp_2xx']])
            add_stat('HTTPCode_Backend_3XX', f[num_map['hrsp_3xx']])
            add_stat('HTTPCode_Backend_4XX', f[num_map['hrsp_4xx']])
            add_stat('HTTPCode_Backend_5XX', f[num_map['hrsp_5xx']])
        else:
            if f[num_map['status']] == 'UP':
                up_count = up_count + 1
            else:
                down_count = down_count + 1
        if f[num_map['check_duration']] != '':
            latency = max(float(f[num_map['check_duration']]), latency)

    # note: haproxy's check_duration is in ms, but Latency is in seconds
    add_stat('Latency', str(latency / 1000), unit='Seconds')
    add_stat('HealthyHostCount', str(up_count))
    add_stat('UnHealthyHostCount', str(down_count))


def send_stats(info):
    LOG.info(str(info))
    cmd_str = "curl -X PUT -H \'Content-Type:\' --data-binary \'%s\' %s" % \
               (json.dumps(info), url)

    cmd = CommandRunner(cmd_str)
    cmd.run()
    LOG.info(cmd.stdout)

if args.haproxy:
    lb_data = {'Namespace': 'AWS/ELB'}
    parse_haproxy_unix_socket(lb_data)
    send_stats(lb_data)

if not args.haproxy:
    send_stats(data)

